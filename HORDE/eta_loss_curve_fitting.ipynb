{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# q_error distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "\n",
    "plt.rcParams['axes.linewidth']=3\n",
    "plt.rcParams['font.size']=18\n",
    "plt.rcParams['lines.linewidth']=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def drawing(dataset,version):\n",
    "    result_addr=\"./lecarb/estimator/mine/tree_inference_result/valid_\"+dataset+\"_\"+version+\".pkl\"\n",
    "    with open(result_addr, 'rb') as f:\n",
    "        [inference_result,inference_time] = pickle.load(f)\n",
    "\n",
    "    addr=\"./lecarb/estimator/mine/learning_model_prediction/valid_\"+dataset+\"_\"+version+\".pkl\"\n",
    "    with open(addr, 'rb') as f:\n",
    "        [prediction,label,data_length] = pickle.load(f)\n",
    "        \n",
    "       \n",
    "    prediction=prediction.cpu().detach().numpy()\n",
    "    count_prediction=[float(i) for i in prediction]\n",
    "\n",
    "    prediction_values=sorted(Counter(count_prediction).keys(),key=lambda x:x,reverse=False)\n",
    "    \n",
    "    label=np.around(label*data_length)\n",
    "    label=[i[0] for i in label]\n",
    "    \n",
    "\n",
    "    loss=[] \n",
    "    t=[]\n",
    "    mean_qerror=[]\n",
    "    for threshold in prediction_values:\n",
    "        add_time=0\n",
    "        q_error=[]\n",
    "        for i in range(len(prediction)):\n",
    "            if prediction[i]<=threshold:\n",
    "                q_error.append(1)\n",
    "                add_time+=inference_time[i]\n",
    "            else:\n",
    "                p=np.around(prediction[i]*data_length)[0]\n",
    "                \n",
    "                \n",
    "                l=label[i]\n",
    "                if p==0 and l==0:\n",
    "                    q_error.append(1)\n",
    "                elif p==0:\n",
    "                    q_error.append(l)\n",
    "                elif l==0:\n",
    "                    q_error.append(p)\n",
    "                else:\n",
    "                    q_error.append(max(p/l,l/p))\n",
    "        add_time=add_time*1000/10000\n",
    "        \n",
    "        loss.append(add_time+np.mean(q_error))\n",
    "        t.append(add_time)\n",
    "        mean_qerror.append(np.mean(q_error))\n",
    "    print(\"best eta:\",prediction_values[loss.index(min(loss))])\n",
    "    \n",
    "    threshold=prediction_values[loss.index(min(loss))]\n",
    "    add_time=0\n",
    "    q_error=[]\n",
    "    turn_to_precise=0\n",
    "    for i in range(len(prediction)):\n",
    "        if prediction[i]<=threshold:\n",
    "            turn_to_precise+=1\n",
    "            q_error.append(1)\n",
    "            add_time+=inference_time[i]\n",
    "        else:\n",
    "            p=np.around(prediction[i]*data_length)[0]\n",
    "            l=label[i]\n",
    "            if p==0 and l==0:\n",
    "                q_error.append(1)\n",
    "            elif p==0:\n",
    "                q_error.append(l)\n",
    "            elif l==0:\n",
    "                q_error.append(p)\n",
    "            else:\n",
    "                q_error.append(max(p/l,l/p))\n",
    "    add_time=add_time*1000/10000\n",
    "    print(\"max:\",np.max(q_error),'99th:',np.percentile(q_error,99),'95th:',np.percentile(q_error,95),'90th:',np.percentile(q_error,90),'75th:',np.percentile(q_error,75),'50th:',np.percentile(q_error,50),'25th:',np.percentile(q_error,25),'mean:',np.mean(q_error))\n",
    "    print(\"average time:\",add_time,\"ms/query\")\n",
    "    print(\"turn_to_precise\",turn_to_precise)\n",
    "    \n",
    "    plt.xlabel('eta')\n",
    "    plt.ylabel('loss')\n",
    "    plt.plot(prediction_values,loss)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.xlabel('eta')\n",
    "    plt.ylabel('incremented time of using tree')\n",
    "    plt.plot(prediction_values,t)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.xlabel('eta')\n",
    "    plt.ylabel('mean q_error after using tree')\n",
    "    plt.plot(prediction_values,mean_qerror)\n",
    "    plt.show()\n",
    "    \n",
    "    return prediction_values,loss,t,mean_qerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit,minimize\n",
    "import matplotlib.pyplot as mpl\n",
    "\n",
    "from sympy import symbols, diff\n",
    "from sympy.functions import exp\n",
    "\n",
    "def func1_for_diff(a,x0,sigma):\n",
    "    x=symbols('x')\n",
    "    f=a*exp(-(x-x0)**2/(2*sigma**2))\n",
    "    derivative_f = diff(f, x)\n",
    "    return f,derivative_f\n",
    "\n",
    "def func2_for_diff(a,x0,sigma):\n",
    "    x=symbols('x')\n",
    "    f=a*exp(-(x-x0)**2/(2*sigma**2))+1\n",
    "    derivative_f = diff(f, x)\n",
    "    return f,derivative_f\n",
    "\n",
    "# Let's create a function to model and create data\n",
    "def func1(x, a, x0, sigma):\n",
    "    return a*np.exp(-(x-x0)**2/(2*sigma**2))\n",
    "\n",
    "def func2(x, a, x0, sigma):\n",
    "    return a*np.exp(-(x-x0)**2/(2*sigma**2))+1\n",
    "\n",
    "def exponen(x,a,b,lamb):\n",
    "    if type(x)==type([]):\n",
    "        x=np.array(x)\n",
    "    return a-b*np.exp(-(lamb*x))\n",
    "\n",
    "def exponen_for_diff(a,b,lamb):\n",
    "    x=symbols('x')\n",
    "    f=a-b*exp(-(lamb*x))\n",
    "    derivative_f = diff(f, x)\n",
    "    return f,derivative_f\n",
    "\n",
    "def fit2(x,y,fit_type,y_name):\n",
    "    plt.plot(x, y, c='k', label='data')\n",
    "    plt.scatter(x, y)\n",
    "    if fit_type==1:\n",
    "        popt, pcov = curve_fit(exponen, x, y,maxfev=1000000)\n",
    "        ym = exponen(x, popt[0], popt[1], popt[2])\n",
    "    elif fit_type==2:\n",
    "        popt, pcov = curve_fit(func2, x, y,maxfev=1000000)\n",
    "        ym = func2(x, popt[0], popt[1], popt[2])\n",
    "    else:\n",
    "        print(\"wrong type\")\n",
    "        return\n",
    "        \n",
    "    #popt returns the best fit values for parameters of the given model (func)\n",
    "    \n",
    "    plt.xlabel('eta')\n",
    "    plt.ylabel(y_name)\n",
    "    plt.plot(x, ym, c='r', label='fit')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return popt\n",
    "\n",
    "def exponent_func(a,b,lamb):\n",
    "    f=lambda x:a-b*np.exp(-(lamb*x))\n",
    "    return f\n",
    "\n",
    "def func2_func(a,x0,sigma):\n",
    "    f=lambda x:a*np.exp(-(x-x0)**2/(2*sigma**2))+1\n",
    "    return f\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_find_best_eta(prediction_values,t,mean_qerror):\n",
    "    x=symbols('x')\n",
    "    popt1=fit2(prediction_values,t,fit_type=1,y_name='time')\n",
    "    popt2=fit2(prediction_values,mean_qerror,fit_type=2,y_name='mqe')\n",
    "    f1,_=exponen_for_diff(popt1[0],popt1[1],popt1[2])\n",
    "    print(\"a:\",popt1[0])\n",
    "    print('b:',popt1[1])\n",
    "    print('lambda:',popt1[2])\n",
    "    f2,_=func2_for_diff(popt2[0],popt2[1],popt2[2])\n",
    "    print(\"c:\",popt2[0])\n",
    "    print('x0:',popt2[1])\n",
    "    print('sigma:',popt2[2])\n",
    "\n",
    "    f=f1+f2\n",
    "    \n",
    "    print(\"time\",f1)\n",
    "    print(\"mean q error\",f2)\n",
    "    print(f)\n",
    "    print(\"-----------------\")\n",
    "    \n",
    "    func_f1=exponent_func(popt1[0],popt1[1],popt1[2])\n",
    "    func_f2=func2_func(popt2[0],popt2[1],popt2[2])\n",
    "    func_f=lambda x:func_f1(x)+func_f2(x)\n",
    "    result=minimize(func_f,x0=[0.5],method='SLSQP',bounds=[(0,1)])\n",
    "    \n",
    "    \n",
    "    loss=[]\n",
    "    for i in range(len(t)):\n",
    "        loss.append(t[i]+mean_qerror[i])\n",
    "    plt.scatter(prediction_values,loss,label='loss')\n",
    "    \n",
    "    a=[i/10000 for i in range(0,10000)]\n",
    "    b=[f.subs(x,i) for i in a]\n",
    "    plt.plot(a,b,color='r',label='fit')\n",
    "    best_eta=result['x'][0]\n",
    "    print(\"best eta:\",best_eta)\n",
    "    \n",
    "    plt.xlabel('eta')\n",
    "    plt.ylabel('loss')\n",
    "    plt.scatter(best_eta,f.subs(x,best_eta),color='green')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return best_eta,f.subs(x,best_eta),a,b\n",
    "\n",
    "\n",
    "def test_for_best_eta(dataset,version,best_eta):\n",
    "    result_addr=\"./lecarb/estimator/mine/tree_inference_result/\"+dataset+\"_\"+version+\".pkl\"\n",
    "    with open(result_addr, 'rb') as f:\n",
    "        [inference_result,inference_time] = pickle.load(f)\n",
    "\n",
    "    addr=\"./lecarb/estimator/mine/learning_model_prediction/test_\"+dataset+\"_\"+version+\".pkl\"\n",
    "    with open(addr, 'rb') as f:\n",
    "        [prediction,label,data_length] = pickle.load(f)\n",
    "        \n",
    "    label=np.around(label*data_length)\n",
    "    label=[i[0] for i in label]\n",
    "    \n",
    "#     for i in range(100):\n",
    "#         print(label[i],inference_result[i])\n",
    "#     return\n",
    "    \n",
    "    prediction=prediction.cpu().detach().numpy()\n",
    "    add_time=0\n",
    "    q_error=[]\n",
    "    turn_to_precise=0\n",
    "    for i in range(len(prediction)):\n",
    "        if prediction[i]<=best_eta:\n",
    "            q_error.append(1)\n",
    "            turn_to_precise+=1\n",
    "            add_time+=inference_time[i]\n",
    "        else:\n",
    "            p=np.around(prediction[i]*data_length)[0]\n",
    "            l=label[i]\n",
    "            if p==0 and l==0:\n",
    "                q_error.append(1)\n",
    "            elif p==0:\n",
    "                q_error.append(l)\n",
    "            elif l==0:\n",
    "                q_error.append(p)\n",
    "            else:\n",
    "                q_error.append(max(p/l,l/p))\n",
    "    add_time=add_time*1000/10000\n",
    "    print(\"max:\",np.max(q_error),'99th:',np.percentile(q_error,99),'95th:',np.percentile(q_error,95),'90th:',np.percentile(q_error,90),'75th:',np.percentile(q_error,75),'50th:',np.percentile(q_error,50),'25th:',np.percentile(q_error,25),'mean:',np.mean(q_error))\n",
    "    print(\"average incremental time:\",add_time,\"ms/query\")\n",
    "    print(\"turn_to_precise\",turn_to_precise)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eta-loss/time/mean q_error curve\n",
    "\n",
    "t : time\n",
    "\n",
    "mqe : mean q_error\n",
    "\n",
    "$loss=t+mqe$\n",
    "\n",
    "\n",
    "\n",
    "$f(\\eta) = a-be^{-\\lambda \\eta}$\n",
    "\n",
    "$g(\\eta)=1+ae^{-\\frac{(\\eta-\\eta_{0})^{2}}{2\\sigma^{2}}}$\n",
    "\n",
    "$loss(\\eta)=f(\\eta)+g(\\eta)$\n",
    "\n",
    "minimization algorithm: SLSQP(SequentialLeastSquaresProgramming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# census13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_values1,loss1,t1,mean_qerror1=drawing('census13','original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_eta1,best_loss1,fit_x1,fit_y1=fit_and_find_best_eta(prediction_values1,t1,mean_qerror1)\n",
    "test_for_best_eta(\"census13\",'original',best_eta1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# forest10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_values2,loss2,t2,mean_qerror2=drawing('forest10','original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_eta2,best_loss2,fit_x2,fit_y2=fit_and_find_best_eta(prediction_values2,t2,mean_qerror2)\n",
    "test_for_best_eta(\"forest10\",'original',best_eta2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# power7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_values3,loss3,t3,mean_qerror3=drawing('power7','original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_eta3,best_loss3,fit_x3,fit_y3=fit_and_find_best_eta(prediction_values3,t3,mean_qerror3)\n",
    "test_for_best_eta(\"power7\",'original',best_eta3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dmv11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_values4,loss4,t4,mean_qerror4=drawing('dmv11','original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_eta4,best_loss4,fit_x4,fit_y4=fit_and_find_best_eta(prediction_values4,t4,mean_qerror4)\n",
    "test_for_best_eta(\"dmv11\",'original',best_eta4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
